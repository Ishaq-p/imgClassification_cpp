{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39140fa3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'showData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_217584/2900250708.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcomposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdataset_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./Data/rawData\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomposed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mshowData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'showData' is not defined"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMAGE_SIZE = 16\n",
    "composed = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), transforms.ToTensor()])\n",
    "dataset_train = dsets.MNIST(root=\"./Data/rawData\", train=True, download=True, transform=composed)\n",
    "showData(dataset_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "581ee70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078,\n",
       "           0.0196, 0.0824, 0.1059, 0.0980, 0.1843, 0.0902, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0039, 0.0824, 0.2157, 0.3765, 0.5333,\n",
       "           0.6118, 0.7373, 0.6627, 0.6196, 0.7647, 0.3020, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0118, 0.3804, 0.8549, 0.9294, 0.9569,\n",
       "           0.8784, 0.9294, 0.4588, 0.2510, 0.2000, 0.0510, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.1569, 0.4588, 0.7765, 0.7608,\n",
       "           0.2353, 0.3137, 0.1412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.4275, 0.6941,\n",
       "           0.1137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980, 0.6235,\n",
       "           0.5647, 0.2627, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.2039,\n",
       "           0.6549, 0.8039, 0.3490, 0.0392, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039,\n",
       "           0.0980, 0.5137, 0.8863, 0.3255, 0.0078, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0980,\n",
       "           0.3373, 0.6667, 0.9608, 0.3882, 0.0078, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0627, 0.3294, 0.7098,\n",
       "           0.9137, 0.8706, 0.5647, 0.1373, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0118, 0.0784, 0.3137, 0.5843, 0.8980, 0.8824,\n",
       "           0.6235, 0.2667, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.2627, 0.7059, 0.9020, 0.8745, 0.7059, 0.2941,\n",
       "           0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.1333, 0.2706, 0.2549, 0.1647, 0.0510, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "befe7e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showData(dataSample):\n",
    "    plt.imshow(dataSample[0].numpy().reshape(IMAGE_SIZE, IMAGE_SIZE), cmap='gray')\n",
    "    plt.title('y = '+ str(dataSample[1]))\n",
    "\n",
    "def saveImgToPMG(imgArray, index):\n",
    "    width, height = 16, 16\n",
    "    p_num = width * height\n",
    "    arr = np.random.randint(0,255, p_num)\n",
    "    \n",
    "    fout = open(f\"Data/finalData/trainData/{index}.pmg\", 'wb')\n",
    "#     fout = open(f\"{index}.pmg\", 'wb')\n",
    "    pgmHeader = 'P2' + '\\n' + str(width) + ' ' + str(height) + '\\n' + str(255) +  '\\n'\n",
    "    pgmHeader_byte = bytearray(pgmHeader,'utf-8')\n",
    "    fout.write(pgmHeader_byte)\n",
    "    \n",
    "    img = np.reshape(arr, (height, width))\n",
    "    \n",
    "    wholeImg = \"\"\n",
    "    for i in imgArray:\n",
    "        eachRow =\"\"\n",
    "        for j in i:\n",
    "            eachRow+=str(int(j*1000000000))+\" \"\n",
    "        wholeImg+=eachRow+\"\\n\"\n",
    "    wholeImg_byte = bytearray(wholeImg, 'utf-8')\n",
    "    fout.write(wholeImg_byte)\n",
    "    \n",
    "    fout.close()\n",
    "\n",
    "def saveWeightsToPMG(imgArray, index, width, height):\n",
    "#     width, height = 16, 25\n",
    "    p_num = width * height\n",
    "    arr = np.random.randint(0,255, p_num)\n",
    "    \n",
    "    fout = open(f\"{index}.pmg\", 'wb')\n",
    "    pgmHeader = 'P2' + '\\n' + str(width) + ' ' + str(height) + '\\n' + str(1000000000) +  '\\n'\n",
    "    pgmHeader_byte = bytearray(pgmHeader,'utf-8')\n",
    "    fout.write(pgmHeader_byte)\n",
    "    \n",
    "    img = np.reshape(arr, (height, width))\n",
    "    \n",
    "    wholeImg = \"\"\n",
    "    try:\n",
    "        for i in imgArray:\n",
    "            eachRow =\"\"\n",
    "            for j in i:\n",
    "                eachRow+=str(int(j*1e9))+\" \"\n",
    "            wholeImg+=eachRow+\"\\n\"\n",
    "    except Exception as e:\n",
    "        print(i)\n",
    "    wholeImg_byte = bytearray(wholeImg, 'utf-8')\n",
    "    fout.write(wholeImg_byte)\n",
    "    \n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564c5d49",
   "metadata": {},
   "source": [
    "### saving all the MNIST imgs in PMG format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05d67c12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for k in range(60000):\n",
    "#     saveImgToPMG(dataset_train[k][0].numpy()[0], k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aa4eb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_2dTo1d(lis_2d):\n",
    "    weights_string=[]\n",
    "    for i in lis_2d:\n",
    "        for ii in i:\n",
    "            weights_string.append(ii.item())\n",
    "    return weights_string\n",
    "#     print(weights_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f69532aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.097444184\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"model.pt\")\n",
    "model.keys()\n",
    "\n",
    "# saveWeightsToPMG([array_2dTo1d(i[0]) for i in model['cnn1.weight'].numpy()], 'modelWeights/cnn1/cnn1_weights', 16,25)\n",
    "\n",
    "# for flterNum in range(32):\n",
    "#     saveWeightsToPMG([array_2dTo1d(i) for i in model['cnn2.weight'][flterNum].numpy()], f'modelWeights/cnn2/cnn2_weights{flterNum}', 16, 25)\n",
    "\n",
    "# saveWeightsToPMG(model['fc1.weight'].numpy(), f'modelWeights/fc1/fc1_weights', 10, 512)\n",
    "\n",
    "saveWeightsToPMG(list(model['fc1.bias'].numpy()), f'modelWeights/fc1/fc1_biases', 2, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
